{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPE4cY3BUTAD3okvLWSK2cA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quzzal-Khanam/CodeAlpha_Handwritten_Character-Recognition/blob/main/Handwritten_Character_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install idx2numpy matplotlib --quiet\n",
        "!pip install stdlib-list --quiet\n",
        "print('\\n  All required packages installed successfully')"
      ],
      "metadata": {
        "id": "Ge64-d2zHxH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# System & File Operations\n",
        "import os\n",
        "from os import listdir\n",
        "import random\n",
        "import sys\n",
        "import importlib\n",
        "import warnings\n",
        "from stdlib_list import stdlib_list\n",
        "\n",
        "# Numerical & Data Processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "BYbzGgneIABV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Image Processing\n",
        "import cv2"
      ],
      "metadata": {
        "id": "1ndNvT-KIBjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow / Keras for Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, Flatten, Conv2D, MaxPooling2D,\n",
        "    BatchNormalization, Input, Activation\n",
        ")\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend, losses, optimizers\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ],
      "metadata": {
        "id": "4NAu7HZpIGts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer Learning\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# Evaluation Metrics (Scikit-learn)\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, confusion_matrix,\n",
        "    mean_absolute_error, mean_squared_error\n",
        ")"
      ],
      "metadata": {
        "id": "LsUiuvCXIKeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# EMNIST Data Handling\n",
        "import idx2numpy\n",
        "\n",
        "print('\\n  All libraries imported successfully')"
      ],
      "metadata": {
        "id": "xx80PRG1IOof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the version of the import modules"
      ],
      "metadata": {
        "id": "9GLnpPSOISSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get stdlib modules for current Python version\n",
        "STANDARD_LIBS = set(stdlib_list())\n",
        "\n",
        "def is_std_lib(pkg_name):\n",
        "    return pkg_name in STANDARD_LIBS\n",
        "\n",
        "def get_top_level_module_name(module_name):\n",
        "    # Take only the first part of dotted module name\n",
        "    return module_name.split('.')[0]\n",
        "\n",
        "def get_versions_of_imported_packages():\n",
        "    versions = {}\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        for mod_name, module in sys.modules.items():\n",
        "            if not module:\n",
        "                continue\n",
        "            top_pkg = get_top_level_module_name(mod_name)\n",
        "            # Skip stdlib modules and builtins\n",
        "            if is_std_lib(top_pkg) or top_pkg in ('builtins',):\n",
        "                continue\n",
        "            # Skip duplicates (process once)\n",
        "            if top_pkg in versions:\n",
        "                continue\n",
        "            try:\n",
        "                imported_mod = importlib.import_module(top_pkg)\n",
        "                ver = getattr(imported_mod, '__version__', None)\n",
        "                if ver:\n",
        "                    versions[top_pkg] = ver\n",
        "            except Exception:\n",
        "                # Ignore import/version errors silently\n",
        "                pass\n",
        "    return versions\n",
        "\n",
        "# Get versions\n",
        "versions = get_versions_of_imported_packages()\n",
        "\n",
        "print(\"Detected external packages and versions from imported modules:\")\n",
        "for pkg in sorted(versions):\n",
        "    print(f\"{pkg}>={versions[pkg]}\")"
      ],
      "metadata": {
        "id": "4NJlCJr5ITPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "print(\"GPU:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Check for TPU (used less commonly unless you're training huge models)\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print(\"TPU found:\", tpu)\n",
        "except ValueError:\n",
        "    print(\"TPU not found.\")"
      ],
      "metadata": {
        "id": "MSgCdKPNIi7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Global Helper Functions"
      ],
      "metadata": {
        "id": "48xy_YKhIpTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function: Fix orientation of images (flip vertically and rotate)\n",
        "def fix_emnist_orientation(images):\n",
        "    return np.transpose(images, (0, 2, 1))[:, ::-1, :]\n",
        "\n",
        "# Define the global class_map for EMNIST Balanced\n",
        "# This should be accessible to all helper functions\n",
        "class_map_global = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabdefghnqrt\"\n",
        "\n",
        "# Function: Show sample images\n",
        "def show_samples(images, labels, num=5):\n",
        "    for i in range(num):\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray') # .squeeze() for single channel images\n",
        "        plt.title(f'Label: {class_map_global[labels[i]]}')  # Use global class_map\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Function: Plot class distribution\n",
        "def plot_class_distribution(labels, dataset_name=\"\"):\n",
        "    counts = Counter(labels)\n",
        "    classes = sorted(counts.keys())\n",
        "    frequencies = [counts[k] for k in classes]\n",
        "    letters = [label_to_letter(k) for k in classes] # This will use the updated label_to_letter\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.bar(letters, frequencies, color='skyblue')\n",
        "    plt.title(f'Class Distribution in {dataset_name} Set')\n",
        "    plt.xlabel('Class (Letter)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(axis='y')\n",
        "    plt.show()\n",
        "    # Print numerical summary\n",
        "    print(f\"\\n{dataset_name} class distribution:\")\n",
        "    for k in classes:\n",
        "        print(f\"{label_to_letter(k)}: {counts[k]}\")\n",
        "\n",
        "# Function: Visualize sample images with labels\n",
        "def visualize_samples(images, labels, num_samples=9):\n",
        "    plt.figure(figsize=(9, 9))\n",
        "    # Display the first num_samples in a grid (e.g., 3x3 if num_samples==9)\n",
        "    grid_size = int(np.sqrt(num_samples))\n",
        "    for i in range(num_samples):\n",
        "        plt.subplot(grid_size, grid_size, i + 1)\n",
        "        # images[i,:,:,0] because the images are grayscale\n",
        "        plt.imshow(images[i, :, :, 0], cmap='gray')\n",
        "        # Convert numeric label to corresponding uppercase letter using class_map_global\n",
        "        plt.title(f'Label: {class_map_global[labels[i]]}')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Function: Convert Label to Letter (updated to use global class_map)\n",
        "def label_to_letter(label):\n",
        "    if 0 <= label < len(class_map_global):\n",
        "        return class_map_global[label]\n",
        "    return '?' # Handle out-of-range labels\n",
        "\n",
        "# Function: Show Predictions\n",
        "def show_predictions(images, true_labels, pred_labels, num_samples=10):\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(num_samples):\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "        plt.title(f\"GT: {label_to_letter(true_labels[i])}\\nPred: {label_to_letter(pred_labels[i])}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Function:Plot confusion matrix\n",
        "def plot_confusion_matrix(cm, title):\n",
        "    plt.figure(figsize=(12,10))\n",
        "    # Ensure class_labels used here is the correct one, likely global or passed\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=[label_to_letter(i) for i in range(cm.shape[1])],\n",
        "                yticklabels=[label_to_letter(i) for i in range(cm.shape[0])])\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Function: Analyze confusion matrix\n",
        "def analyze_confusion_matrix(conf_matrix, class_labels):\n",
        "    # Get True Positives for each class (diagonal of confusion matrix)\n",
        "    true_positives = np.diag(conf_matrix)\n",
        "\n",
        "    # Total samples per class (sum of rows)\n",
        "    total_per_class = conf_matrix.sum(axis=1)\n",
        "\n",
        "    # Avoid divide by zero\n",
        "    class_accuracies = np.where(total_per_class == 0, 0, true_positives / total_per_class)\n",
        "\n",
        "    # Get best and worst performing letters\n",
        "    best_idx = np.argmax(class_accuracies)\n",
        "    worst_idx = np.argmin(class_accuracies)\n",
        "\n",
        "    # Ensure class_labels matches the actual number of classes in the confusion matrix\n",
        "    num_classes_in_cm = conf_matrix.shape[0]\n",
        "    if len(class_labels) < num_classes_in_cm:\n",
        "        # This should ideally not happen if labels are corrected upstream\n",
        "        # For now, extend if possible or log warning\n",
        "        print(f\"Warning: class_labels length ({len(class_labels)}) mismatch with confusion matrix classes ({num_classes_in_cm})\")\n",
        "        # Fallback for plotting if needed, but the true fix is upstream.\n",
        "        # We'll use the correct mapping for printing below.\n",
        "\n",
        "    print(f\"Best Predicted Letter: {label_to_letter(best_idx)} with accuracy {class_accuracies[best_idx]*100:.2f}%\")\n",
        "    print(f\"Worst Predicted Letter: {label_to_letter(worst_idx)} with accuracy {class_accuracies[worst_idx]*100:.2f}%\")\n",
        "\n",
        "    # Print all accuracies using the global class_map_global for correct labels\n",
        "    print(\"\\n Class-wise accuracies:\")\n",
        "    for i, acc in enumerate(class_accuracies):\n",
        "        if i < len(class_map_global): # Ensure index is within bounds of class_map_global\n",
        "            print(f\"{class_map_global[i]}: {acc*100:.2f}%\")\n",
        "        else:\n",
        "            print(f\"Unknown_Class_{i}: {acc*100:.2f}%\") # Fallback for unexpected extra classes\n",
        "\n",
        "    return class_accuracies\n",
        "\n",
        "# Function: Annotate bars horizontally (moved from previous cell to here as it's a helper)\n",
        "def annotate_bars_horizontal(ax, fmt='both', fontsize=10, spacing=0.005):\n",
        "    for bar in ax.patches:\n",
        "        width = bar.get_width()\n",
        "        if fmt == 'count':\n",
        "            label = f'{width:.2f}'\n",
        "        elif fmt == 'percent':\n",
        "            label = f'{width * 100:.1f}%'\n",
        "        elif fmt == 'both':\n",
        "            label = f'{width:.2f} ({width * 100:.1f}%)'\n",
        "        else:\n",
        "            label = ''\n",
        "        ax.annotate(label,\n",
        "                    (width + spacing, bar.get_y() + bar.get_height() / 2),\n",
        "                    ha='left', va='center', fontsize=fontsize)\n",
        "\n",
        "\n",
        "print('\\n  All functions loaded successfully')"
      ],
      "metadata": {
        "id": "pl4YGUVHIrhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Load EMNIST Data\n"
      ],
      "metadata": {
        "id": "UUibkZ-GJIBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install missing tools\n",
        "!pip install opendatasets --upgrade --quiet\n",
        "\n",
        "import os\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 2. Set your Credentials\n",
        "os.environ['KAGGLE_USERNAME'] = \"quzzalkhanam\"\n",
        "os.environ['KAGGLE_KEY'] = \"6f8746e077d1451c433f7a264a6a7c58\"\n",
        "\n",
        "# 3. Download Dataset (Using the URL directly)\n",
        "dataset_url = \"https://www.kaggle.com/datasets/crawford/emnist\"\n",
        "od.download(dataset_url)\n",
        "\n",
        "# 4. Load the Data\n",
        "# The file is saved in a folder named 'emnist'\n",
        "file_path = './emnist/emnist-balanced-train.csv'\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    # Load the CSV into the 'data' variable\n",
        "    data = pd.read_csv(file_path, header=None)\n",
        "\n",
        "    # Extract Labels and Images\n",
        "    y = data.iloc[:, 0].values\n",
        "    X = data.iloc[:, 1:].values.reshape(-1, 28, 28)\n",
        "\n",
        "    # Apply the Rotation Fix (The Kaggle Secret)\n",
        "    X = np.array([np.rot90(np.fliplr(img)) for img in X])\n",
        "    X = X.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "    # Success Mapping\n",
        "    class_map = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabdefghnqrt\"\n",
        "    print(f\" 'data' is now defined! Loaded {len(data)} rows.\")\n",
        "\n",
        "    # Show a sample to prove it works\n",
        "    plt.imshow(X[0].reshape(28,28), cmap='gray')\n",
        "    plt.title(f\"Target: {class_map[y[0]]}\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\" Error: File not found. Check if the download completed.\")"
      ],
      "metadata": {
        "id": "rv7p0HyTM4rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix Image Orientation"
      ],
      "metadata": {
        "id": "oqVV4ddgJRjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the fix function so the computer knows what it is\n",
        "def fix_emnist_orientation(img_data):\n",
        "    # Reshape to 28x28 squares\n",
        "    img_data = img_data.reshape(-1, 28, 28)\n",
        "    # Rotate and Flip (The Kaggle standard fix)\n",
        "    fixed_data = np.array([np.rot90(np.fliplr(img)) for img in img_data])\n",
        "    # Reshape back for the CNN (Adding the 1 color channel)\n",
        "    return fixed_data.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# 2. Link  'X' data to the names\n",
        "# (This fixes the 'name not defined' error)\n",
        "train_images = X  # X was created in our previous successful step\n",
        "\n",
        "# 3. RUN THE FIX\n",
        "train_images = fix_emnist_orientation(train_images)\n",
        "\n",
        "print(f\" Orientation Fixed! train_images shape: {train_images.shape}\")\n",
        "\n",
        "# 4. Visual Confirmation\n",
        "plt.imshow(train_images[0].reshape(28,28), cmap='gray')\n",
        "plt.title(\"Orientation Check: Should be Upright\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IabpRHwMJV4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Image"
      ],
      "metadata": {
        "id": "dKbafSxuJYEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Split the data (80% for training, 20% for testing)\n",
        "# This creates the 'test_images'\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\" Variables defined! train_images: {train_images.shape}, test_images: {test_images.shape}\")\n",
        "\n",
        "train_images = train_images.astype(np.float32) / 255.0\n",
        "test_images = test_images.astype(np.float32) / 255.0\n",
        "\n",
        "print(\" Normalization complete.\")"
      ],
      "metadata": {
        "id": "Wri2157qJcHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Labels Writable"
      ],
      "metadata": {
        "id": "pvts8qlRJefY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels writable\n",
        "train_labels = train_labels.copy()\n",
        "test_labels = test_labels.copy()"
      ],
      "metadata": {
        "id": "sFewj3VxJfE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8VECeG9pJnZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preliminary Data Review\n",
        "\n",
        "Check Shape of Training and Test Data"
      ],
      "metadata": {
        "id": "pTpKEyjzJpzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train images shape: {train_images.shape}\")\n",
        "print(f\"Train labels shape: {train_labels.shape}\")\n",
        "print(f\"Test images shape: {test_images.shape}\")\n",
        "print(f\"Test labels shape: {test_labels.shape}\")"
      ],
      "metadata": {
        "id": "LTKjhWjVJsF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize a Few Samples"
      ],
      "metadata": {
        "id": "K2Bkc0EiJz5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_samples(train_images, train_labels, num=5)"
      ],
      "metadata": {
        "id": "Xa_RJCboJ0bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for Class Distribution"
      ],
      "metadata": {
        "id": "qJZz8-3fJ2sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to training and test sets\n",
        "plot_class_distribution(train_labels, dataset_name=\"Training\")\n",
        "plot_class_distribution(test_labels, dataset_name=\"Test\")"
      ],
      "metadata": {
        "id": "cU6yX-iIJ97U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "ePcdp7eUKALC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "# Convert the training and test images and labels into separate Python lists\n",
        "for img, label in zip(train_images, train_labels):\n",
        "    X_train.append(img)\n",
        "    y_train.append(label)\n",
        "\n",
        "for img, label in zip(test_images, test_labels):\n",
        "    X_test.append(img)\n",
        "    y_test.append(label)\n",
        "\n",
        "# Convert the list back to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Print the shape of the newly created arrays\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)"
      ],
      "metadata": {
        "id": "DTZvcRH9KEZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Random Seeds for Reproducibility"
      ],
      "metadata": {
        "id": "FfUAiWaLKH90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)"
      ],
      "metadata": {
        "id": "5Bv1Qg6jKK9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Channel Dimension to Grayscale Images"
      ],
      "metadata": {
        "id": "bKXMHpPhKNjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "4M9qH8VoKPnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply One-hot Encoding for Categorical Classification"
      ],
      "metadata": {
        "id": "tKF-wlZ6KRt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Change 26 to 47 to accommodate Digits and extra Letters\n",
        "num_classes = 47\n",
        "\n",
        "# 2. Convert to categorical\n",
        "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "print(f\"Success! Labels converted for {num_classes} classes.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3n3dI5GFKT5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Images and their Labels"
      ],
      "metadata": {
        "id": "HjXRg2nGKWWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_samples(X_train, train_labels, num_samples=9)"
      ],
      "metadata": {
        "id": "3-xumTrwKYT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and Train Model"
      ],
      "metadata": {
        "id": "oYomrBFmKhlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(28, 28, 1)),              # Explicit input layer\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(26, activation='softmax')        # 26 output classes corresponding to A-Z\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "n7D7NJywKif1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model"
      ],
      "metadata": {
        "id": "vhxQfzEcKoTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "\n",
        "# This clears the internal TensorFlow state\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(28, 28, 1)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(47, activation='softmax') # Ensure this is 47\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xuq99YUNKo_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train_cat,\n",
        "    validation_data=(X_test, y_test_cat),\n",
        "    epochs=10,\n",
        "    batch_size=128\n",
        ")"
      ],
      "metadata": {
        "id": "Mxxme6eqSqOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Model Performance"
      ],
      "metadata": {
        "id": "AJ5cMzHpKtE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Model Performance\n",
        "plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EqVGKGAbKtz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation and Prediction on Test Data"
      ],
      "metadata": {
        "id": "kSiFB5h9Kw-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the Test Data"
      ],
      "metadata": {
        "id": "SysqSQ6gK4EU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Make predictions on test data\n",
        "pred_probs = model.predict(X_test, verbose=0)\n",
        "pred_labels = pred_probs.argmax(axis=1)"
      ],
      "metadata": {
        "id": "vOkfHrnSK4o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare and Visualize Predictions"
      ],
      "metadata": {
        "id": "M6fYSpVmK68g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_predictions(X_test, y_test, pred_labels, num_samples=10)"
      ],
      "metadata": {
        "id": "iL71hDosK883"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Confusion Matrix for Train/Test Data"
      ],
      "metadata": {
        "id": "ukVKC9-aK_GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get train predictions\n",
        "train_pred_probs = model.predict(X_train, verbose=0)\n",
        "train_pred_labels = train_pred_probs.argmax(axis=1)\n",
        "\n",
        "# Create confusion matrix\n",
        "train_cm = confusion_matrix(y_train, train_pred_labels)\n",
        "test_cm = confusion_matrix(y_test, pred_labels)\n",
        "\n",
        "# Define class labels (A-Z)\n",
        "class_labels = [chr(i) for i in range(ord('A'), ord('Z')+1)]"
      ],
      "metadata": {
        "id": "KbkfwATGLB4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(train_cm, 'Confusion Matrix - Training Data')"
      ],
      "metadata": {
        "id": "LwEcPtZTLFu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(test_cm, 'Confusion Matrix - Test Data')"
      ],
      "metadata": {
        "id": "Ab7mFvqCLII0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Per-class Accuracy"
      ],
      "metadata": {
        "id": "-wnm-o-QLKYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. The FULL 47-class mapping for EMNIST Balanced\n",
        "full_emnist_labels = list(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabdefghnqrt\")\n",
        "\n",
        "def analyze_confusion_matrix_safe(conf_matrix, labels_list):\n",
        "    # Get True Positives (diagonal) and Total per class (row sums)\n",
        "    true_positives = np.diag(conf_matrix)\n",
        "    total_per_class = conf_matrix.sum(axis=1)\n",
        "\n",
        "    # Calculate accuracy safely (avoid divide by zero)\n",
        "    class_accuracies = np.where(total_per_class == 0, 0, true_positives / total_per_class)\n",
        "\n",
        "    print(\"\\n--- Class-wise Accuracies ---\")\n",
        "    # Loop ONLY as many times as i have labels to avoid IndexError\n",
        "    num_to_print = min(len(labels_list), len(class_accuracies))\n",
        "\n",
        "    for i in range(num_to_print):\n",
        "        acc = class_accuracies[i]\n",
        "        print(f\"{labels_list[i]}: {acc*100:.2f}%\")\n",
        "\n",
        "    return class_accuracies\n",
        "\n",
        "# 2. Run the safe function\n",
        "test_class_accuracies = analyze_confusion_matrix_safe(test_cm, full_emnist_labels)\n",
        "\n",
        "# 3. Best and Worst\n",
        "best_idx = np.argmax(test_class_accuracies)\n",
        "worst_idx = np.argmin(test_class_accuracies)\n",
        "print(f\"\\n Best Predicted: {full_emnist_labels[best_idx]} ({test_class_accuracies[best_idx]*100:.2f}%)\")\n",
        "print(f\" Worst Predicted: {full_emnist_labels[worst_idx]} ({test_class_accuracies[worst_idx]*100:.2f}%)\")"
      ],
      "metadata": {
        "id": "rMJuKOFALNlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the Result"
      ],
      "metadata": {
        "id": "02AoKkgMLQfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to list of (label, accuracy)\n",
        "accuracy_pairs = list(zip(class_labels, test_class_accuracies))\n",
        "\n",
        "# Sort descending by accuracy\n",
        "sorted_accuracies = sorted(accuracy_pairs, key=lambda x: x[1], reverse=False)\n",
        "sorted_labels, sorted_values = zip(*sorted_accuracies)\n",
        "\n",
        "# Plot horizontal bar chart\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "bars = ax.barh(sorted_labels, sorted_values, color='cornflowerblue')\n",
        "\n",
        "ax.set_xlabel(\"Accuracy\")\n",
        "ax.set_ylabel(\"Class\")\n",
        "ax.set_title(\"Per-Class Accuracy (Descending Order)\")\n",
        "ax.set_xlim(0, 1)\n",
        "ax.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "ax.margins(x=0.5)\n",
        "\n",
        "for spine in ax.spines.values():\n",
        "    spine.set_visible(False)\n",
        "\n",
        "# Annotate bars horizontally\n",
        "def annotate_bars_horizontal(ax, fmt='both', fontsize=10, spacing=0.005):\n",
        "    for bar in ax.patches:\n",
        "        width = bar.get_width()\n",
        "        if fmt == 'count':\n",
        "            label = f'{width:.2f}'\n",
        "        elif fmt == 'percent':\n",
        "            label = f'{width * 100:.1f}%'\n",
        "        elif fmt == 'both':\n",
        "            label = f'{width:.2f} ({width * 100:.1f}%)'\n",
        "        else:\n",
        "            label = ''\n",
        "        ax.annotate(label,\n",
        "                    (width + spacing, bar.get_y() + bar.get_height() / 2),\n",
        "                    ha='left', va='center', fontsize=fontsize)\n",
        "\n",
        "annotate_bars_horizontal(ax, fmt='percent')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PGScJOFILRHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "# Re-define mapping locally\n",
        "class_map_local = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabdefghnqrt\"\n",
        "\n",
        "def test_model_accuracy(char_idx):\n",
        "    # 1. Find all available samples for this class in the test set\n",
        "    indices = np.where(y_test == char_idx)[0]\n",
        "\n",
        "    if len(indices) == 0:\n",
        "        return \"No data samples found in the test set for this character.\"\n",
        "\n",
        "    # 2. Test up to 100 samples to get a real accuracy percentage\n",
        "    num_to_test = min(len(indices), 100)\n",
        "    test_indices = np.random.choice(indices, num_to_test, replace=False)\n",
        "\n",
        "    correct_count = 0\n",
        "    samples = X_test[test_indices].reshape(-1, 28, 28, 1)\n",
        "\n",
        "    # 3. Batch Predict\n",
        "    predictions = model.predict(samples, verbose=0)\n",
        "    predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    for pred in predicted_labels:\n",
        "        if pred == char_idx:\n",
        "            correct_count += 1\n",
        "\n",
        "    accuracy = (correct_count / num_to_test) * 100\n",
        "\n",
        "    # 4. Return a text-only report\n",
        "    report = (\n",
        "        f\"--- Statistical Report for '{class_map_local[char_idx]}' ---\\n\\n\"\n",
        "        f\"Total Samples Tested: {num_to_test}\\n\"\n",
        "        f\"Correctly Identified: {correct_count}\\n\"\n",
        "        f\"Model Accuracy for this Character: {accuracy:.1f}%\\n\\n\"\n",
        "        f\"Conclusion: \" + (\"Strong Performance\" if accuracy > 80 else \"Needs Improvement\")\n",
        "    )\n",
        "\n",
        "    return report\n",
        "\n",
        "# Create the Simplified UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ðŸ“Š EMNIST Model Accuracy Tester\")\n",
        "    gr.Markdown(\"Select a character to see how well the AI performs across 100 different test samples.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        char_dropdown = gr.Dropdown(\n",
        "            choices=[(f\"Test Character: {class_map_local[i]}\", i) for i in range(47)],\n",
        "            label=\"Select Character to Test\",\n",
        "            value=0\n",
        "        )\n",
        "        test_btn = gr.Button(\"ðŸš€ Run Accuracy Test\")\n",
        "\n",
        "    with gr.Row():\n",
        "        result_text = gr.Textbox(label=\"Test Results\", lines=10)\n",
        "\n",
        "    # Trigger test on selection or button click\n",
        "    test_btn.click(test_model_accuracy, inputs=char_dropdown, outputs=result_text)\n",
        "    char_dropdown.change(test_model_accuracy, inputs=char_dropdown, outputs=result_text)\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "hWFuqXYkV1E_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}